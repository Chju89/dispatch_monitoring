{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aeb56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚öôÔ∏è C√†i ƒë·∫∑t th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "!pip install -q torch torchvision pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af2df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÅ Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8583676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† Load m√¥ h√¨nh v√† ƒë·ªãnh nghƒ©a th√¥ng tin\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import cv2, pickle\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "video_path = \"/content/drive/MyDrive/dispatch/video_shortened.mp4\"\n",
    "model_path = \"/content/drive/MyDrive/dispatch/resnet18_dispatch.pt\"\n",
    "log_path = \"/content/drive/MyDrive/dispatch/bbox_tracking_log.pkl\"\n",
    "\n",
    "output_csv = Path(\"classification_result.csv\")\n",
    "ui_objects_path = Path(\"ui_objects.pkl\")\n",
    "\n",
    "# Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load model\n",
    "model = models.resnet18(pretrained=False, num_classes=6)\n",
    "state_dict = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Transform ·∫£nh ƒë·∫ßu v√†o\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Class mapping\n",
    "id_to_class = {\n",
    "    0: 'dish_empty',\n",
    "    1: 'dish_kakigori',\n",
    "    2: 'dish_not_empty',\n",
    "    3: 'tray_empty',\n",
    "    4: 'tray_kakigori',\n",
    "    5: 'tray_not_empty'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b55e838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Ch·∫°y ph√¢n lo·∫°i\n",
    "with open(log_path, \"rb\") as f:\n",
    "    bbox_data = pickle.load(f)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "results = []\n",
    "ui_data = {}\n",
    "\n",
    "for frame_idx, objs in bbox_data.items():\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "    success, frame = cap.read()\n",
    "    if not success:\n",
    "        print(f\"[!] Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame {frame_idx}\")\n",
    "        continue\n",
    "\n",
    "    height, width = frame.shape[:2]\n",
    "    ui_data[frame_idx] = []\n",
    "\n",
    "    for obj in objs:\n",
    "        cls = obj[\"object\"]\n",
    "        track_id = obj[\"id\"]\n",
    "        x, y, w, h = obj[\"bbox\"]\n",
    "\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        x2 = min(x + w, width)\n",
    "        y2 = min(y + h, height)\n",
    "\n",
    "        crop = frame[y:y2, x:x2]\n",
    "        if crop.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop_pil = Image.fromarray(cv2.cvtColor(crop, cv2.COLOR_BGR2RGB))\n",
    "        input_tensor = transform(crop_pil).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(input_tensor)\n",
    "            prob = F.softmax(output, dim=1)\n",
    "            pred = torch.argmax(prob, dim=1).item()\n",
    "            confidence = prob[0][pred].item()\n",
    "            label_name = id_to_class[pred]\n",
    "\n",
    "        ui_data[frame_idx].append({\n",
    "            \"id\": track_id,\n",
    "            \"object\": cls,\n",
    "            \"status\": label_name.split(\"_\")[1],\n",
    "            \"bbox\": obj[\"bbox\"],\n",
    "            \"confidence\": round(confidence, 4)\n",
    "        })\n",
    "\n",
    "        results.append({\n",
    "            \"frame\": frame_idx,\n",
    "            \"track_id\": track_id,\n",
    "            \"object\": cls,\n",
    "            \"predicted\": pred,\n",
    "            \"predicted_label\": label_name,\n",
    "            \"confidence\": round(confidence, 4)\n",
    "        })\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aec09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ L∆∞u k·∫øt qu·∫£\n",
    "pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "with open(ui_objects_path, \"wb\") as f:\n",
    "    pickle.dump(ui_data, f)\n",
    "\n",
    "print(\"‚úÖ Ph√¢n lo·∫°i ho√†n t·∫•t. K·∫øt qu·∫£ l∆∞u t·∫°i:\", output_csv, \"v√†\", ui_objects_path)\n",
    "\n",
    "# üì§ T·∫£i v·ªÅ\n",
    "from google.colab import files\n",
    "files.download(\"classification_result.csv\")\n",
    "files.download(\"ui_objects.pkl\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
