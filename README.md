# ğŸšš Dispatch Monitoring System (Realtime Version)

A production-ready, **real-time monitoring system** for kitchen dispatch areas using object detection, tracking, and classification directly on video. Includes feedback loop, model retraining, and full MLOps integration with **MLflow**.

---

## ğŸŒŸ Features

- ğŸ§  **Object Detection**: YOLOv8 custom model (e.g., `yolov8m_dispatch_colab`)
- ğŸ›°ï¸ **Object Tracking**: DeepSORT with consistent tracking IDs
- ğŸ§ª **Classification**: ResNet18 classifier with 6 dish/tray states:
  - `dish_empty`, `dish_not_empty`, `dish_kakigori`  
  - `tray_empty`, `tray_not_empty`, `tray_kakigori`
- ğŸ¯ **Realtime Inference**: End-to-end processing per video frame
- ğŸ§¾ **Interactive Feedback**:
  - View frame-by-frame detection results
  - Delete any incorrect object by ID
  - Adjust classification via dropdowns
- ğŸ” **Feedback Loop**: Persist changes to JSON and enable retraining
- ğŸ“Š **MLflow Integration**: Tracks model training, evaluation, metrics & artifacts
- ğŸ³ **Dockerized Deployment**: Fully containerized with Docker Compose

---

## ğŸ”„ Pipeline Overview

```mermaid
graph TD
    A[Input Video (mp4)] --> B[Detection + Tracking (YOLOv8 + DeepSORT)]
    B --> C[Realtime Classification (ResNet18)]
    C --> D[Draw & Show Bounding Boxes]
    D --> E[Feedback UI (Streamlit)]
    E --> F[Export to Feedback Logs (JSON)]
    F --> G[Retraining (optional)]
```

---

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ app.py                         # Streamlit app (now real-time)
â”œâ”€â”€ models/                        # Trained models
â”‚   â”œâ”€â”€ detection/best.pt          # YOLOv8 model
â”‚   â””â”€â”€ classification/resnet18_dispatch.pt  # Full ResNet model
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/video_shortened.mp4    # Input video
â”‚   â””â”€â”€ feedback/                  # User feedback in JSON
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ tracking.py                # (legacy) tracking script
â”‚   â”œâ”€â”€ classify.py                # (legacy) classification script
â”‚   â”œâ”€â”€ retrain.py                 # Classifier retraining using feedback
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ train_classifier_colab.ipynb
â”‚   â””â”€â”€ train_yolov8_colab.ipynb
â”œâ”€â”€ requirements.txt, environment.yaml
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile.app, Dockerfile.mlflow
â””â”€â”€ README.md
```

---

## ğŸš€ Run Locally

### 1. Run the App
```bash
streamlit run app.py
```

### 2. Provide Video Input
- Drop your video in `data/raw/video_shortened.mp4` (or change path in code)

### 3. Classify Frame-by-Frame
- Realtime detection + classification
- Delete wrong objects, correct status via dropdown
- Press **"Apply Change"** to log your feedback

---

## ğŸ§ª Retraining

After collecting enough feedback:

```bash
python src/retrain.py
```

> Your corrected feedback is saved in `data/feedback/*.json`, and can be used to update the classifier.

---

## ğŸ§  MLflow Integration

- Automatically logs model params, metrics, and artifacts
- URLs:
  - Streamlit UI: http://localhost:8501
  - MLflow UI: http://localhost:5000

---

## ğŸ³ Run with Docker
To Clone
```bash
mkdir test_repo && cd test_repo
git clone https://github.com/Chju89/dispatch_monitoring.git
cd dispatch_monitoring
```
To run:
```bash
docker-compose up --build
```

To stop:
```bash
docker-compose down --volumes --remove-orphans
```

---

## ğŸ“¤ Output Artifacts

| Step                | Output File                          |
|---------------------|--------------------------------------|
| Realtime Feedback   | `data/feedback/*.json`               |
| Trained Classifier  | `models/classification/resnet18_dispatch.pt` |
| Trained Detector    | `models/detection/best.pt`           |
| MLflow Artifacts    | `mlruns/`, `mlartifacts/`            |

---

## ğŸ‘¤ Author

**Nguyen Quang Trieu**  
MLOps Enthusiast | AI Learner | Senior Rigging Artist  
ğŸ“« [quangtrieu.sp@gmail.com](mailto:quangtrieu.sp@gmail.com)
