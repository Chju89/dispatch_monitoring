# Dispatch Monitoring System ğŸš€

A lightweight end-to-end MLOps pipeline to detect, track, and classify objects in a kitchen dispatch area, with feedback loop and retraining capabilities.

---

## ğŸŒŸ Features

* ğŸ‘€ Object Detection: YOLOv8-based model to detect `dish` and `tray`
* ğŸ›ï¸ Object Tracking: DeepSORT to maintain track IDs across frames
* ğŸ§ƒ Classification: ResNet18 model to classify cropped objects into 6 classes:

  * `dish/empty`, `dish/not_empty`, `dish/kakigori`
  * `tray/empty`, `tray/not_empty`, `tray/kakigori`
* ğŸ“ˆ MLflow Integration: Logs metrics, parameters, artifacts of both models
* ğŸ“Š Feedback UI: Streamlit app allows user to correct wrong predictions
* ğŸ”„ Retraining Script: Model improvement loop based on user feedback

---

## ğŸ”„ Pipeline Overview

```mermaid
graph TD
    A[Input Video / Frames] --> B[Detection (YOLOv8)]
    B --> C[Tracking (DeepSORT)]
    C --> D[Crop Objects by ID]
    D --> E[Classification (ResNet18)]
    E --> F[Overlay Labels on Frame]
    F --> G[Save Video + Frames]
    G --> H[Feedback UI]
    H --> I[Feedback Log]
    I --> J[Retrain Script]
```

---

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Raw video + dataset
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ tracking/               # Tracked frames, crops, result.csv
â”‚   â”‚   â”œâ”€â”€ feedback.csv            # Feedback from user
â”‚   â”‚   â”œâ”€â”€ output_video.mp4        # Final labeled video
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detection/best.pt           # YOLOv8 trained model
â”‚   â”œâ”€â”€ classification/resnet18.pt # Classifier model
â”œâ”€â”€ notebooks/                      # Colab training notebooks
â”œâ”€â”€ src/                            # Source code
â”‚   â”œâ”€â”€ detection.py
â”‚   â”œâ”€â”€ tracking.py
â”‚   â”œâ”€â”€ classify.py
â”‚   â”œâ”€â”€ extract_frames.py
â”‚   â”œâ”€â”€ feedback_ui.py
â”‚   â”œâ”€â”€ retrain.py
â”œâ”€â”€ app.py                          # Streamlit app for feedback
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“š Model Training

### 1. Train YOLOv8 (on Colab)

```python
from ultralytics import YOLO
model = YOLO('yolov8n.pt')
model.train(data='dataset.yaml', epochs=100, imgsz=640, batch=16, name='yolov8n_dispatch')
```

### 2. Train ResNet18 Classifier

```python
# Colab notebook: train_classifier_colab.ipynb
# Logs model + metrics to MLflow
```

---

## ğŸ› ï¸ Usage

### 1. Extract frames

```bash
python src/extract_frames.py
```

### 2. Run detection + tracking

```bash
python src/tracking.py
```

### 3. Run classification

```bash
python src/classify.py
```

### 4. Launch Feedback UI

```bash
streamlit run app.py
```

### 5. Retrain from feedback (optional)

```bash
python src/retrain.py
```

---

## ğŸ“Š Output Files

| Step            | Output Path                                         |
| --------------- | --------------------------------------------------- |
| Frames w/ label | `data/processed/tracking/frames_with_id/`           |
| Cropped objects | `data/processed/tracking/crops/`                    |
| Classification  | `data/processed/tracking/classification_result.csv` |
| Feedback        | `data/processed/feedback.csv`                       |
| Final video     | `data/processed/output_video.mp4`                   |

---

## ğŸ” MLflow Tracking

| Run Name                  | Description                  |
| ------------------------- | ---------------------------- |
| `yolov8_detection_v1`     | YOLOv8 model + metrics       |
| `resnet18_classification` | ResNet18 training & accuracy |
| `relog_yolov8n`           | Relogged model from Colab    |

---

## ğŸ“– Feedback Loop (Bonus)

* Giao diá»‡n ngÆ°á»i dÃ¹ng (`Streamlit`) cho phÃ©p chá»n `track_id` vÃ  sá»­a nhÃ£n
* Feedback Ä‘Æ°á»£c lÆ°u vÃ o `feedback.csv`
* Script retrain sáº½ dÃ¹ng cÃ¡c sample nÃ y Ä‘á»ƒ fine-tune láº¡i mÃ´ hÃ¬nh phÃ¢n loáº¡i

---

## ğŸ’¼ Author

Nguyen Quang Trieu
MLOps Enthusiast | AI Learner | Senior Rigging Artist | Former Physics Teacher

